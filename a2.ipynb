{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = '../data/stage1_train/'\n",
    "TEST_PATH = '../data/stage1_test/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "\n",
    "\n",
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 670/670 [03:49<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 65/65 [00:01<00:00, 51.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEYCAYAAAATaEB+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ad45f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEYCAYAAAATaEB+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTcjMUrkJmVmq/wflZ5ukKNmzTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1359a550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(train_ids))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128, 128, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 8)  224         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 8)  584         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 8)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 16)   1168        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 16)   2320        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 16)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 32)   4640        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 32)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 64)   18496       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 128)    73856       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 16, 16, 64)   32832       conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 128)  0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 64)   73792       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 32, 32, 32)   8224        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 64)   0           conv2d_transpose_6[0][0]         \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 32)   18464       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 64, 64, 16)   2064        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 32)   0           conv2d_transpose_7[0][0]         \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 64, 16)   4624        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 64, 16)   2320        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 128, 128, 8)  520         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128, 128, 16) 0           conv2d_transpose_8[0][0]         \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 128, 8)  1160        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 128, 128, 8)  584         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 128, 128, 1)  9           conv2d_37[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 485,817\n",
      "Trainable params: 485,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 536 samples, validate on 134 samples\n",
      "Epoch 1/10\n",
      "528/536 [============================>.] - ETA: 2:14 - loss: 0.7261 - mean_iou: 0.0000e+ - ETA: 1:24 - loss: 0.7091 - mean_iou: 0.1998   - ETA: 1:07 - loss: 0.7065 - mean_iou: 0.27 - ETA: 58s - loss: 0.7029 - mean_iou: 0.3073 - ETA: 52s - loss: 0.7005 - mean_iou: 0.328 - ETA: 48s - loss: 0.6986 - mean_iou: 0.344 - ETA: 45s - loss: 0.6971 - mean_iou: 0.356 - ETA: 42s - loss: 0.6959 - mean_iou: 0.365 - ETA: 40s - loss: 0.6951 - mean_iou: 0.371 - ETA: 39s - loss: 0.6943 - mean_iou: 0.376 - ETA: 37s - loss: 0.6936 - mean_iou: 0.380 - ETA: 36s - loss: 0.6928 - mean_iou: 0.384 - ETA: 35s - loss: 0.6918 - mean_iou: 0.387 - ETA: 34s - loss: 0.6910 - mean_iou: 0.389 - ETA: 33s - loss: 0.6902 - mean_iou: 0.391 - ETA: 32s - loss: 0.6894 - mean_iou: 0.393 - ETA: 31s - loss: 0.6889 - mean_iou: 0.395 - ETA: 30s - loss: 0.6884 - mean_iou: 0.396 - ETA: 29s - loss: 0.6868 - mean_iou: 0.398 - ETA: 28s - loss: 0.6858 - mean_iou: 0.399 - ETA: 28s - loss: 0.6850 - mean_iou: 0.400 - ETA: 27s - loss: 0.6835 - mean_iou: 0.401 - ETA: 26s - loss: 0.6816 - mean_iou: 0.402 - ETA: 25s - loss: 0.6765 - mean_iou: 0.403 - ETA: 25s - loss: 0.6737 - mean_iou: 0.403 - ETA: 24s - loss: 0.6709 - mean_iou: 0.404 - ETA: 23s - loss: 0.6734 - mean_iou: 0.405 - ETA: 23s - loss: 0.6690 - mean_iou: 0.405 - ETA: 22s - loss: 0.6636 - mean_iou: 0.406 - ETA: 21s - loss: 0.6611 - mean_iou: 0.406 - ETA: 21s - loss: 0.6585 - mean_iou: 0.407 - ETA: 20s - loss: 0.6553 - mean_iou: 0.407 - ETA: 19s - loss: 0.6534 - mean_iou: 0.408 - ETA: 19s - loss: 0.6517 - mean_iou: 0.408 - ETA: 18s - loss: 0.6500 - mean_iou: 0.409 - ETA: 18s - loss: 0.6467 - mean_iou: 0.409 - ETA: 17s - loss: 0.6420 - mean_iou: 0.409 - ETA: 16s - loss: 0.6400 - mean_iou: 0.410 - ETA: 16s - loss: 0.6369 - mean_iou: 0.410 - ETA: 15s - loss: 0.6322 - mean_iou: 0.411 - ETA: 15s - loss: 0.6304 - mean_iou: 0.411 - ETA: 14s - loss: 0.6276 - mean_iou: 0.411 - ETA: 13s - loss: 0.6248 - mean_iou: 0.411 - ETA: 13s - loss: 0.6202 - mean_iou: 0.412 - ETA: 12s - loss: 0.6165 - mean_iou: 0.412 - ETA: 12s - loss: 0.6162 - mean_iou: 0.412 - ETA: 11s - loss: 0.6131 - mean_iou: 0.413 - ETA: 11s - loss: 0.6083 - mean_iou: 0.413 - ETA: 10s - loss: 0.6054 - mean_iou: 0.413 - ETA: 9s - loss: 0.6019 - mean_iou: 0.413 - ETA: 9s - loss: 0.5984 - mean_iou: 0.41 - ETA: 8s - loss: 0.5950 - mean_iou: 0.41 - ETA: 8s - loss: 0.5912 - mean_iou: 0.41 - ETA: 7s - loss: 0.5897 - mean_iou: 0.41 - ETA: 6s - loss: 0.5863 - mean_iou: 0.41 - ETA: 6s - loss: 0.5842 - mean_iou: 0.41 - ETA: 5s - loss: 0.5830 - mean_iou: 0.41 - ETA: 5s - loss: 0.5847 - mean_iou: 0.41 - ETA: 4s - loss: 0.5821 - mean_iou: 0.41 - ETA: 4s - loss: 0.5800 - mean_iou: 0.41 - ETA: 3s - loss: 0.5783 - mean_iou: 0.41 - ETA: 2s - loss: 0.5759 - mean_iou: 0.41 - ETA: 2s - loss: 0.5738 - mean_iou: 0.41 - ETA: 1s - loss: 0.5718 - mean_iou: 0.41 - ETA: 1s - loss: 0.5698 - mean_iou: 0.41 - ETA: 0s - loss: 0.5674 - mean_iou: 0.4164\n",
      "Epoch 00001: val_loss improved from inf to 0.43225, saving model to model-dsbowl2018-1.h5\n",
      "536/536 [==============================] - 43s 81ms/step - loss: 0.5666 - mean_iou: 0.4165 - val_loss: 0.4322 - val_mean_iou: 0.4244\n",
      "Epoch 2/10\n",
      "528/536 [============================>.] - ETA: 37s - loss: 0.3690 - mean_iou: 0.424 - ETA: 36s - loss: 0.3787 - mean_iou: 0.424 - ETA: 36s - loss: 0.3762 - mean_iou: 0.425 - ETA: 36s - loss: 0.4134 - mean_iou: 0.425 - ETA: 35s - loss: 0.4207 - mean_iou: 0.425 - ETA: 34s - loss: 0.4183 - mean_iou: 0.425 - ETA: 33s - loss: 0.4381 - mean_iou: 0.425 - ETA: 32s - loss: 0.4503 - mean_iou: 0.425 - ETA: 32s - loss: 0.4503 - mean_iou: 0.425 - ETA: 31s - loss: 0.4435 - mean_iou: 0.425 - ETA: 30s - loss: 0.4434 - mean_iou: 0.425 - ETA: 30s - loss: 0.4463 - mean_iou: 0.425 - ETA: 29s - loss: 0.4534 - mean_iou: 0.424 - ETA: 29s - loss: 0.4534 - mean_iou: 0.424 - ETA: 28s - loss: 0.4513 - mean_iou: 0.424 - ETA: 27s - loss: 0.4510 - mean_iou: 0.424 - ETA: 27s - loss: 0.4525 - mean_iou: 0.424 - ETA: 26s - loss: 0.4478 - mean_iou: 0.424 - ETA: 26s - loss: 0.4531 - mean_iou: 0.424 - ETA: 25s - loss: 0.4557 - mean_iou: 0.424 - ETA: 25s - loss: 0.4554 - mean_iou: 0.424 - ETA: 24s - loss: 0.4552 - mean_iou: 0.424 - ETA: 23s - loss: 0.4529 - mean_iou: 0.424 - ETA: 23s - loss: 0.4494 - mean_iou: 0.424 - ETA: 22s - loss: 0.4484 - mean_iou: 0.424 - ETA: 22s - loss: 0.4497 - mean_iou: 0.424 - ETA: 21s - loss: 0.4476 - mean_iou: 0.424 - ETA: 21s - loss: 0.4485 - mean_iou: 0.424 - ETA: 20s - loss: 0.4485 - mean_iou: 0.424 - ETA: 20s - loss: 0.4456 - mean_iou: 0.424 - ETA: 19s - loss: 0.4458 - mean_iou: 0.424 - ETA: 19s - loss: 0.4408 - mean_iou: 0.424 - ETA: 18s - loss: 0.4384 - mean_iou: 0.424 - ETA: 17s - loss: 0.4383 - mean_iou: 0.424 - ETA: 17s - loss: 0.4413 - mean_iou: 0.424 - ETA: 16s - loss: 0.4409 - mean_iou: 0.424 - ETA: 16s - loss: 0.4371 - mean_iou: 0.424 - ETA: 15s - loss: 0.4344 - mean_iou: 0.424 - ETA: 15s - loss: 0.4340 - mean_iou: 0.424 - ETA: 14s - loss: 0.4332 - mean_iou: 0.424 - ETA: 14s - loss: 0.4321 - mean_iou: 0.424 - ETA: 13s - loss: 0.4315 - mean_iou: 0.424 - ETA: 13s - loss: 0.4323 - mean_iou: 0.424 - ETA: 12s - loss: 0.4325 - mean_iou: 0.424 - ETA: 11s - loss: 0.4320 - mean_iou: 0.424 - ETA: 11s - loss: 0.4323 - mean_iou: 0.424 - ETA: 10s - loss: 0.4322 - mean_iou: 0.424 - ETA: 10s - loss: 0.4322 - mean_iou: 0.424 - ETA: 9s - loss: 0.4316 - mean_iou: 0.424 - ETA: 9s - loss: 0.4287 - mean_iou: 0.42 - ETA: 8s - loss: 0.4270 - mean_iou: 0.42 - ETA: 8s - loss: 0.4234 - mean_iou: 0.42 - ETA: 7s - loss: 0.4243 - mean_iou: 0.42 - ETA: 7s - loss: 0.4227 - mean_iou: 0.42 - ETA: 6s - loss: 0.4225 - mean_iou: 0.42 - ETA: 5s - loss: 0.4204 - mean_iou: 0.42 - ETA: 5s - loss: 0.4171 - mean_iou: 0.42 - ETA: 4s - loss: 0.4170 - mean_iou: 0.42 - ETA: 4s - loss: 0.4172 - mean_iou: 0.42 - ETA: 3s - loss: 0.4169 - mean_iou: 0.42 - ETA: 3s - loss: 0.4163 - mean_iou: 0.42 - ETA: 2s - loss: 0.4173 - mean_iou: 0.42 - ETA: 2s - loss: 0.4154 - mean_iou: 0.42 - ETA: 1s - loss: 0.4140 - mean_iou: 0.42 - ETA: 1s - loss: 0.4141 - mean_iou: 0.42 - ETA: 0s - loss: 0.4133 - mean_iou: 0.4243\n",
      "Epoch 00002: val_loss improved from 0.43225 to 0.33519, saving model to model-dsbowl2018-1.h5\n",
      "536/536 [==============================] - 40s 75ms/step - loss: 0.4116 - mean_iou: 0.4243 - val_loss: 0.3352 - val_mean_iou: 0.4240\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528/536 [============================>.] - ETA: 34s - loss: 0.3541 - mean_iou: 0.424 - ETA: 35s - loss: 0.3291 - mean_iou: 0.424 - ETA: 34s - loss: 0.3647 - mean_iou: 0.424 - ETA: 34s - loss: 0.3827 - mean_iou: 0.424 - ETA: 33s - loss: 0.3895 - mean_iou: 0.424 - ETA: 33s - loss: 0.3682 - mean_iou: 0.424 - ETA: 32s - loss: 0.3534 - mean_iou: 0.424 - ETA: 32s - loss: 0.3762 - mean_iou: 0.424 - ETA: 32s - loss: 0.3914 - mean_iou: 0.424 - ETA: 31s - loss: 0.3811 - mean_iou: 0.424 - ETA: 31s - loss: 0.3854 - mean_iou: 0.423 - ETA: 30s - loss: 0.3770 - mean_iou: 0.423 - ETA: 30s - loss: 0.3826 - mean_iou: 0.423 - ETA: 29s - loss: 0.3807 - mean_iou: 0.423 - ETA: 29s - loss: 0.3789 - mean_iou: 0.423 - ETA: 28s - loss: 0.3717 - mean_iou: 0.423 - ETA: 27s - loss: 0.3747 - mean_iou: 0.423 - ETA: 27s - loss: 0.3745 - mean_iou: 0.423 - ETA: 26s - loss: 0.3720 - mean_iou: 0.423 - ETA: 26s - loss: 0.3760 - mean_iou: 0.423 - ETA: 25s - loss: 0.3754 - mean_iou: 0.423 - ETA: 24s - loss: 0.3742 - mean_iou: 0.423 - ETA: 24s - loss: 0.3731 - mean_iou: 0.423 - ETA: 23s - loss: 0.3755 - mean_iou: 0.423 - ETA: 23s - loss: 0.3775 - mean_iou: 0.423 - ETA: 22s - loss: 0.3719 - mean_iou: 0.423 - ETA: 22s - loss: 0.3724 - mean_iou: 0.423 - ETA: 21s - loss: 0.3685 - mean_iou: 0.423 - ETA: 20s - loss: 0.3623 - mean_iou: 0.423 - ETA: 20s - loss: 0.3660 - mean_iou: 0.423 - ETA: 19s - loss: 0.3620 - mean_iou: 0.423 - ETA: 19s - loss: 0.3583 - mean_iou: 0.423 - ETA: 18s - loss: 0.3603 - mean_iou: 0.423 - ETA: 18s - loss: 0.3610 - mean_iou: 0.423 - ETA: 17s - loss: 0.3615 - mean_iou: 0.423 - ETA: 16s - loss: 0.3616 - mean_iou: 0.423 - ETA: 16s - loss: 0.3620 - mean_iou: 0.423 - ETA: 15s - loss: 0.3589 - mean_iou: 0.423 - ETA: 15s - loss: 0.3567 - mean_iou: 0.423 - ETA: 14s - loss: 0.3565 - mean_iou: 0.423 - ETA: 14s - loss: 0.3566 - mean_iou: 0.423 - ETA: 13s - loss: 0.3570 - mean_iou: 0.423 - ETA: 13s - loss: 0.3552 - mean_iou: 0.423 - ETA: 12s - loss: 0.3553 - mean_iou: 0.423 - ETA: 11s - loss: 0.3539 - mean_iou: 0.423 - ETA: 11s - loss: 0.3529 - mean_iou: 0.423 - ETA: 10s - loss: 0.3524 - mean_iou: 0.423 - ETA: 10s - loss: 0.3494 - mean_iou: 0.423 - ETA: 9s - loss: 0.3476 - mean_iou: 0.423 - ETA: 9s - loss: 0.3456 - mean_iou: 0.42 - ETA: 8s - loss: 0.3437 - mean_iou: 0.42 - ETA: 8s - loss: 0.3432 - mean_iou: 0.42 - ETA: 7s - loss: 0.3416 - mean_iou: 0.42 - ETA: 7s - loss: 0.3412 - mean_iou: 0.42 - ETA: 6s - loss: 0.3399 - mean_iou: 0.42 - ETA: 5s - loss: 0.3374 - mean_iou: 0.42 - ETA: 5s - loss: 0.3368 - mean_iou: 0.42 - ETA: 4s - loss: 0.3358 - mean_iou: 0.42 - ETA: 4s - loss: 0.3360 - mean_iou: 0.42 - ETA: 3s - loss: 0.3364 - mean_iou: 0.42 - ETA: 3s - loss: 0.3341 - mean_iou: 0.42 - ETA: 2s - loss: 0.3310 - mean_iou: 0.42 - ETA: 2s - loss: 0.3297 - mean_iou: 0.42 - ETA: 1s - loss: 0.3292 - mean_iou: 0.42 - ETA: 1s - loss: 0.3270 - mean_iou: 0.42 - ETA: 0s - loss: 0.3254 - mean_iou: 0.4234\n",
      "Epoch 00003: val_loss improved from 0.33519 to 0.25257, saving model to model-dsbowl2018-1.h5\n",
      "536/536 [==============================] - 40s 75ms/step - loss: 0.3231 - mean_iou: 0.4234 - val_loss: 0.2526 - val_mean_iou: 0.4239\n",
      "Epoch 4/10\n",
      "528/536 [============================>.] - ETA: 35s - loss: 0.3221 - mean_iou: 0.424 - ETA: 34s - loss: 0.3585 - mean_iou: 0.424 - ETA: 34s - loss: 0.3330 - mean_iou: 0.423 - ETA: 34s - loss: 0.3158 - mean_iou: 0.423 - ETA: 33s - loss: 0.2966 - mean_iou: 0.423 - ETA: 32s - loss: 0.2887 - mean_iou: 0.423 - ETA: 32s - loss: 0.2835 - mean_iou: 0.423 - ETA: 31s - loss: 0.2808 - mean_iou: 0.423 - ETA: 31s - loss: 0.2843 - mean_iou: 0.423 - ETA: 30s - loss: 0.2776 - mean_iou: 0.423 - ETA: 30s - loss: 0.2736 - mean_iou: 0.423 - ETA: 29s - loss: 0.2720 - mean_iou: 0.423 - ETA: 29s - loss: 0.2759 - mean_iou: 0.423 - ETA: 29s - loss: 0.2731 - mean_iou: 0.423 - ETA: 28s - loss: 0.2749 - mean_iou: 0.423 - ETA: 28s - loss: 0.2771 - mean_iou: 0.423 - ETA: 27s - loss: 0.2737 - mean_iou: 0.423 - ETA: 27s - loss: 0.2809 - mean_iou: 0.423 - ETA: 26s - loss: 0.2776 - mean_iou: 0.423 - ETA: 25s - loss: 0.2733 - mean_iou: 0.423 - ETA: 25s - loss: 0.2672 - mean_iou: 0.423 - ETA: 24s - loss: 0.2740 - mean_iou: 0.423 - ETA: 24s - loss: 0.2704 - mean_iou: 0.423 - ETA: 23s - loss: 0.2636 - mean_iou: 0.423 - ETA: 23s - loss: 0.2609 - mean_iou: 0.423 - ETA: 22s - loss: 0.2564 - mean_iou: 0.423 - ETA: 21s - loss: 0.2581 - mean_iou: 0.423 - ETA: 21s - loss: 0.2572 - mean_iou: 0.423 - ETA: 20s - loss: 0.2562 - mean_iou: 0.424 - ETA: 20s - loss: 0.2522 - mean_iou: 0.424 - ETA: 19s - loss: 0.2523 - mean_iou: 0.424 - ETA: 19s - loss: 0.2519 - mean_iou: 0.424 - ETA: 18s - loss: 0.2505 - mean_iou: 0.424 - ETA: 18s - loss: 0.2494 - mean_iou: 0.424 - ETA: 17s - loss: 0.2502 - mean_iou: 0.424 - ETA: 16s - loss: 0.2499 - mean_iou: 0.424 - ETA: 16s - loss: 0.2509 - mean_iou: 0.424 - ETA: 15s - loss: 0.2509 - mean_iou: 0.424 - ETA: 15s - loss: 0.2481 - mean_iou: 0.424 - ETA: 14s - loss: 0.2479 - mean_iou: 0.425 - ETA: 14s - loss: 0.2442 - mean_iou: 0.425 - ETA: 13s - loss: 0.2430 - mean_iou: 0.425 - ETA: 13s - loss: 0.2415 - mean_iou: 0.425 - ETA: 12s - loss: 0.2399 - mean_iou: 0.425 - ETA: 12s - loss: 0.2392 - mean_iou: 0.425 - ETA: 11s - loss: 0.2377 - mean_iou: 0.425 - ETA: 11s - loss: 0.2368 - mean_iou: 0.426 - ETA: 10s - loss: 0.2364 - mean_iou: 0.426 - ETA: 10s - loss: 0.2376 - mean_iou: 0.426 - ETA: 9s - loss: 0.2351 - mean_iou: 0.426 - ETA: 8s - loss: 0.2330 - mean_iou: 0.42 - ETA: 8s - loss: 0.2308 - mean_iou: 0.42 - ETA: 7s - loss: 0.2313 - mean_iou: 0.42 - ETA: 7s - loss: 0.2290 - mean_iou: 0.42 - ETA: 6s - loss: 0.2279 - mean_iou: 0.42 - ETA: 6s - loss: 0.2282 - mean_iou: 0.42 - ETA: 5s - loss: 0.2278 - mean_iou: 0.42 - ETA: 5s - loss: 0.2257 - mean_iou: 0.42 - ETA: 4s - loss: 0.2244 - mean_iou: 0.42 - ETA: 3s - loss: 0.2217 - mean_iou: 0.42 - ETA: 3s - loss: 0.2214 - mean_iou: 0.42 - ETA: 2s - loss: 0.2201 - mean_iou: 0.42 - ETA: 2s - loss: 0.2199 - mean_iou: 0.42 - ETA: 1s - loss: 0.2185 - mean_iou: 0.42 - ETA: 1s - loss: 0.2183 - mean_iou: 0.43 - ETA: 0s - loss: 0.2178 - mean_iou: 0.4303\n",
      "Epoch 00004: val_loss improved from 0.25257 to 0.15882, saving model to model-dsbowl2018-1.h5\n",
      "536/536 [==============================] - 41s 77ms/step - loss: 0.2175 - mean_iou: 0.4306 - val_loss: 0.1588 - val_mean_iou: 0.4519\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528/536 [============================>.] - ETA: 42s - loss: 0.1215 - mean_iou: 0.456 - ETA: 40s - loss: 0.1616 - mean_iou: 0.457 - ETA: 38s - loss: 0.1874 - mean_iou: 0.457 - ETA: 37s - loss: 0.1788 - mean_iou: 0.457 - ETA: 36s - loss: 0.1730 - mean_iou: 0.457 - ETA: 35s - loss: 0.1808 - mean_iou: 0.458 - ETA: 34s - loss: 0.1787 - mean_iou: 0.458 - ETA: 33s - loss: 0.1785 - mean_iou: 0.458 - ETA: 33s - loss: 0.1771 - mean_iou: 0.459 - ETA: 32s - loss: 0.1752 - mean_iou: 0.459 - ETA: 31s - loss: 0.1707 - mean_iou: 0.459 - ETA: 31s - loss: 0.1676 - mean_iou: 0.460 - ETA: 30s - loss: 0.1672 - mean_iou: 0.460 - ETA: 29s - loss: 0.1723 - mean_iou: 0.460 - ETA: 29s - loss: 0.1754 - mean_iou: 0.460 - ETA: 28s - loss: 0.1762 - mean_iou: 0.461 - ETA: 28s - loss: 0.1769 - mean_iou: 0.461 - ETA: 27s - loss: 0.1788 - mean_iou: 0.461 - ETA: 27s - loss: 0.1740 - mean_iou: 0.462 - ETA: 26s - loss: 0.1730 - mean_iou: 0.462 - ETA: 25s - loss: 0.1739 - mean_iou: 0.462 - ETA: 25s - loss: 0.1754 - mean_iou: 0.462 - ETA: 24s - loss: 0.1779 - mean_iou: 0.463 - ETA: 24s - loss: 0.1802 - mean_iou: 0.463 - ETA: 23s - loss: 0.1793 - mean_iou: 0.463 - ETA: 23s - loss: 0.1805 - mean_iou: 0.463 - ETA: 22s - loss: 0.1800 - mean_iou: 0.464 - ETA: 22s - loss: 0.1825 - mean_iou: 0.464 - ETA: 21s - loss: 0.1812 - mean_iou: 0.464 - ETA: 20s - loss: 0.1825 - mean_iou: 0.464 - ETA: 20s - loss: 0.1813 - mean_iou: 0.464 - ETA: 19s - loss: 0.1806 - mean_iou: 0.465 - ETA: 19s - loss: 0.1812 - mean_iou: 0.465 - ETA: 18s - loss: 0.1794 - mean_iou: 0.465 - ETA: 18s - loss: 0.1794 - mean_iou: 0.465 - ETA: 17s - loss: 0.1805 - mean_iou: 0.466 - ETA: 16s - loss: 0.1785 - mean_iou: 0.466 - ETA: 16s - loss: 0.1765 - mean_iou: 0.466 - ETA: 15s - loss: 0.1763 - mean_iou: 0.466 - ETA: 15s - loss: 0.1762 - mean_iou: 0.467 - ETA: 14s - loss: 0.1782 - mean_iou: 0.467 - ETA: 13s - loss: 0.1764 - mean_iou: 0.467 - ETA: 13s - loss: 0.1761 - mean_iou: 0.467 - ETA: 12s - loss: 0.1750 - mean_iou: 0.468 - ETA: 12s - loss: 0.1742 - mean_iou: 0.468 - ETA: 11s - loss: 0.1757 - mean_iou: 0.468 - ETA: 11s - loss: 0.1738 - mean_iou: 0.468 - ETA: 10s - loss: 0.1734 - mean_iou: 0.469 - ETA: 9s - loss: 0.1727 - mean_iou: 0.469 - ETA: 9s - loss: 0.1740 - mean_iou: 0.46 - ETA: 8s - loss: 0.1730 - mean_iou: 0.46 - ETA: 8s - loss: 0.1742 - mean_iou: 0.47 - ETA: 7s - loss: 0.1747 - mean_iou: 0.47 - ETA: 7s - loss: 0.1742 - mean_iou: 0.47 - ETA: 6s - loss: 0.1735 - mean_iou: 0.47 - ETA: 6s - loss: 0.1727 - mean_iou: 0.47 - ETA: 5s - loss: 0.1728 - mean_iou: 0.47 - ETA: 4s - loss: 0.1723 - mean_iou: 0.47 - ETA: 4s - loss: 0.1715 - mean_iou: 0.47 - ETA: 3s - loss: 0.1712 - mean_iou: 0.47 - ETA: 3s - loss: 0.1715 - mean_iou: 0.47 - ETA: 2s - loss: 0.1710 - mean_iou: 0.47 - ETA: 2s - loss: 0.1704 - mean_iou: 0.47 - ETA: 1s - loss: 0.1708 - mean_iou: 0.47 - ETA: 1s - loss: 0.1709 - mean_iou: 0.47 - ETA: 0s - loss: 0.1702 - mean_iou: 0.4737\n",
      "Epoch 00005: val_loss improved from 0.15882 to 0.14219, saving model to model-dsbowl2018-1.h5\n",
      "536/536 [==============================] - 41s 76ms/step - loss: 0.1697 - mean_iou: 0.4740 - val_loss: 0.1422 - val_mean_iou: 0.4963\n",
      "Epoch 6/10\n",
      "528/536 [============================>.] - ETA: 35s - loss: 0.1253 - mean_iou: 0.500 - ETA: 34s - loss: 0.1286 - mean_iou: 0.500 - ETA: 34s - loss: 0.1637 - mean_iou: 0.500 - ETA: 33s - loss: 0.1556 - mean_iou: 0.501 - ETA: 33s - loss: 0.1559 - mean_iou: 0.501 - ETA: 33s - loss: 0.1525 - mean_iou: 0.501 - ETA: 32s - loss: 0.1647 - mean_iou: 0.501 - ETA: 32s - loss: 0.1621 - mean_iou: 0.502 - ETA: 32s - loss: 0.1562 - mean_iou: 0.502 - ETA: 32s - loss: 0.1572 - mean_iou: 0.502 - ETA: 31s - loss: 0.1549 - mean_iou: 0.502 - ETA: 31s - loss: 0.1515 - mean_iou: 0.503 - ETA: 30s - loss: 0.1551 - mean_iou: 0.503 - ETA: 29s - loss: 0.1506 - mean_iou: 0.503 - ETA: 29s - loss: 0.1513 - mean_iou: 0.503 - ETA: 28s - loss: 0.1482 - mean_iou: 0.504 - ETA: 28s - loss: 0.1475 - mean_iou: 0.504 - ETA: 27s - loss: 0.1456 - mean_iou: 0.504 - ETA: 26s - loss: 0.1456 - mean_iou: 0.504 - ETA: 26s - loss: 0.1470 - mean_iou: 0.505 - ETA: 25s - loss: 0.1461 - mean_iou: 0.505 - ETA: 25s - loss: 0.1420 - mean_iou: 0.505 - ETA: 24s - loss: 0.1432 - mean_iou: 0.505 - ETA: 24s - loss: 0.1406 - mean_iou: 0.506 - ETA: 23s - loss: 0.1391 - mean_iou: 0.506 - ETA: 23s - loss: 0.1391 - mean_iou: 0.506 - ETA: 22s - loss: 0.1392 - mean_iou: 0.506 - ETA: 22s - loss: 0.1399 - mean_iou: 0.506 - ETA: 21s - loss: 0.1377 - mean_iou: 0.507 - ETA: 21s - loss: 0.1363 - mean_iou: 0.507 - ETA: 20s - loss: 0.1379 - mean_iou: 0.507 - ETA: 19s - loss: 0.1379 - mean_iou: 0.507 - ETA: 19s - loss: 0.1398 - mean_iou: 0.508 - ETA: 18s - loss: 0.1409 - mean_iou: 0.508 - ETA: 18s - loss: 0.1414 - mean_iou: 0.508 - ETA: 17s - loss: 0.1400 - mean_iou: 0.509 - ETA: 17s - loss: 0.1413 - mean_iou: 0.509 - ETA: 16s - loss: 0.1401 - mean_iou: 0.509 - ETA: 15s - loss: 0.1393 - mean_iou: 0.509 - ETA: 15s - loss: 0.1388 - mean_iou: 0.510 - ETA: 14s - loss: 0.1380 - mean_iou: 0.510 - ETA: 14s - loss: 0.1370 - mean_iou: 0.510 - ETA: 13s - loss: 0.1364 - mean_iou: 0.510 - ETA: 13s - loss: 0.1363 - mean_iou: 0.511 - ETA: 12s - loss: 0.1359 - mean_iou: 0.511 - ETA: 11s - loss: 0.1363 - mean_iou: 0.511 - ETA: 11s - loss: 0.1376 - mean_iou: 0.511 - ETA: 10s - loss: 0.1374 - mean_iou: 0.512 - ETA: 10s - loss: 0.1367 - mean_iou: 0.512 - ETA: 9s - loss: 0.1372 - mean_iou: 0.512 - ETA: 8s - loss: 0.1363 - mean_iou: 0.51 - ETA: 8s - loss: 0.1351 - mean_iou: 0.51 - ETA: 7s - loss: 0.1366 - mean_iou: 0.51 - ETA: 7s - loss: 0.1363 - mean_iou: 0.51 - ETA: 6s - loss: 0.1369 - mean_iou: 0.51 - ETA: 6s - loss: 0.1362 - mean_iou: 0.51 - ETA: 5s - loss: 0.1364 - mean_iou: 0.51 - ETA: 5s - loss: 0.1361 - mean_iou: 0.51 - ETA: 4s - loss: 0.1362 - mean_iou: 0.51 - ETA: 3s - loss: 0.1355 - mean_iou: 0.51 - ETA: 3s - loss: 0.1350 - mean_iou: 0.51 - ETA: 2s - loss: 0.1344 - mean_iou: 0.51 - ETA: 2s - loss: 0.1345 - mean_iou: 0.51 - ETA: 1s - loss: 0.1340 - mean_iou: 0.51 - ETA: 1s - loss: 0.1340 - mean_iou: 0.51 - ETA: 0s - loss: 0.1340 - mean_iou: 0.5165\n",
      "Epoch 00006: val_loss improved from 0.14219 to 0.11730, saving model to model-dsbowl2018-1.h5\n",
      "536/536 [==============================] - 41s 77ms/step - loss: 0.1336 - mean_iou: 0.5168 - val_loss: 0.1173 - val_mean_iou: 0.5385\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528/536 [============================>.] - ETA: 35s - loss: 0.1164 - mean_iou: 0.543 - ETA: 34s - loss: 0.1294 - mean_iou: 0.543 - ETA: 34s - loss: 0.1190 - mean_iou: 0.543 - ETA: 33s - loss: 0.1093 - mean_iou: 0.543 - ETA: 33s - loss: 0.1184 - mean_iou: 0.544 - ETA: 32s - loss: 0.1225 - mean_iou: 0.544 - ETA: 32s - loss: 0.1191 - mean_iou: 0.544 - ETA: 31s - loss: 0.1221 - mean_iou: 0.545 - ETA: 31s - loss: 0.1236 - mean_iou: 0.545 - ETA: 30s - loss: 0.1235 - mean_iou: 0.545 - ETA: 29s - loss: 0.1215 - mean_iou: 0.545 - ETA: 29s - loss: 0.1263 - mean_iou: 0.546 - ETA: 28s - loss: 0.1253 - mean_iou: 0.546 - ETA: 28s - loss: 0.1244 - mean_iou: 0.546 - ETA: 27s - loss: 0.1203 - mean_iou: 0.546 - ETA: 27s - loss: 0.1205 - mean_iou: 0.546 - ETA: 26s - loss: 0.1221 - mean_iou: 0.547 - ETA: 26s - loss: 0.1228 - mean_iou: 0.547 - ETA: 25s - loss: 0.1251 - mean_iou: 0.547 - ETA: 25s - loss: 0.1229 - mean_iou: 0.547 - ETA: 24s - loss: 0.1258 - mean_iou: 0.548 - ETA: 24s - loss: 0.1252 - mean_iou: 0.548 - ETA: 23s - loss: 0.1248 - mean_iou: 0.548 - ETA: 23s - loss: 0.1231 - mean_iou: 0.548 - ETA: 22s - loss: 0.1231 - mean_iou: 0.548 - ETA: 21s - loss: 0.1224 - mean_iou: 0.549 - ETA: 21s - loss: 0.1215 - mean_iou: 0.549 - ETA: 20s - loss: 0.1223 - mean_iou: 0.549 - ETA: 20s - loss: 0.1196 - mean_iou: 0.549 - ETA: 19s - loss: 0.1192 - mean_iou: 0.549 - ETA: 19s - loss: 0.1189 - mean_iou: 0.550 - ETA: 18s - loss: 0.1210 - mean_iou: 0.550 - ETA: 18s - loss: 0.1216 - mean_iou: 0.550 - ETA: 17s - loss: 0.1208 - mean_iou: 0.550 - ETA: 17s - loss: 0.1208 - mean_iou: 0.551 - ETA: 16s - loss: 0.1201 - mean_iou: 0.551 - ETA: 15s - loss: 0.1200 - mean_iou: 0.551 - ETA: 15s - loss: 0.1191 - mean_iou: 0.551 - ETA: 14s - loss: 0.1186 - mean_iou: 0.551 - ETA: 14s - loss: 0.1184 - mean_iou: 0.552 - ETA: 13s - loss: 0.1196 - mean_iou: 0.552 - ETA: 13s - loss: 0.1186 - mean_iou: 0.552 - ETA: 12s - loss: 0.1170 - mean_iou: 0.552 - ETA: 12s - loss: 0.1175 - mean_iou: 0.552 - ETA: 11s - loss: 0.1170 - mean_iou: 0.553 - ETA: 11s - loss: 0.1174 - mean_iou: 0.553 - ETA: 10s - loss: 0.1192 - mean_iou: 0.553 - ETA: 10s - loss: 0.1209 - mean_iou: 0.553 - ETA: 9s - loss: 0.1204 - mean_iou: 0.553 - ETA: 9s - loss: 0.1203 - mean_iou: 0.55 - ETA: 8s - loss: 0.1201 - mean_iou: 0.55 - ETA: 7s - loss: 0.1210 - mean_iou: 0.55 - ETA: 7s - loss: 0.1209 - mean_iou: 0.55 - ETA: 6s - loss: 0.1202 - mean_iou: 0.55 - ETA: 6s - loss: 0.1197 - mean_iou: 0.55 - ETA: 5s - loss: 0.1197 - mean_iou: 0.55 - ETA: 5s - loss: 0.1205 - mean_iou: 0.55 - ETA: 4s - loss: 0.1192 - mean_iou: 0.55 - ETA: 4s - loss: 0.1188 - mean_iou: 0.55 - ETA: 3s - loss: 0.1192 - mean_iou: 0.55 - ETA: 3s - loss: 0.1187 - mean_iou: 0.55 - ETA: 2s - loss: 0.1182 - mean_iou: 0.55 - ETA: 2s - loss: 0.1180 - mean_iou: 0.55 - ETA: 1s - loss: 0.1185 - mean_iou: 0.55 - ETA: 1s - loss: 0.1184 - mean_iou: 0.55 - ETA: 0s - loss: 0.1182 - mean_iou: 0.5570\n",
      "Epoch 00007: val_loss improved from 0.11730 to 0.10718, saving model to model-dsbowl2018-1.h5\n",
      "536/536 [==============================] - 40s 74ms/step - loss: 0.1185 - mean_iou: 0.5572 - val_loss: 0.1072 - val_mean_iou: 0.5740\n",
      "Epoch 8/10\n",
      "528/536 [============================>.] - ETA: 35s - loss: 0.0971 - mean_iou: 0.577 - ETA: 34s - loss: 0.0909 - mean_iou: 0.577 - ETA: 34s - loss: 0.0895 - mean_iou: 0.577 - ETA: 33s - loss: 0.0947 - mean_iou: 0.577 - ETA: 33s - loss: 0.0909 - mean_iou: 0.577 - ETA: 32s - loss: 0.1070 - mean_iou: 0.577 - ETA: 32s - loss: 0.1014 - mean_iou: 0.578 - ETA: 31s - loss: 0.1083 - mean_iou: 0.578 - ETA: 31s - loss: 0.1065 - mean_iou: 0.578 - ETA: 30s - loss: 0.1121 - mean_iou: 0.578 - ETA: 30s - loss: 0.1142 - mean_iou: 0.578 - ETA: 29s - loss: 0.1156 - mean_iou: 0.579 - ETA: 29s - loss: 0.1136 - mean_iou: 0.579 - ETA: 28s - loss: 0.1152 - mean_iou: 0.579 - ETA: 28s - loss: 0.1175 - mean_iou: 0.579 - ETA: 27s - loss: 0.1157 - mean_iou: 0.579 - ETA: 27s - loss: 0.1128 - mean_iou: 0.579 - ETA: 27s - loss: 0.1145 - mean_iou: 0.580 - ETA: 26s - loss: 0.1174 - mean_iou: 0.580 - ETA: 25s - loss: 0.1171 - mean_iou: 0.580 - ETA: 25s - loss: 0.1167 - mean_iou: 0.580 - ETA: 24s - loss: 0.1167 - mean_iou: 0.580 - ETA: 24s - loss: 0.1160 - mean_iou: 0.580 - ETA: 23s - loss: 0.1138 - mean_iou: 0.581 - ETA: 23s - loss: 0.1144 - mean_iou: 0.581 - ETA: 22s - loss: 0.1135 - mean_iou: 0.581 - ETA: 22s - loss: 0.1116 - mean_iou: 0.581 - ETA: 21s - loss: 0.1156 - mean_iou: 0.581 - ETA: 21s - loss: 0.1165 - mean_iou: 0.581 - ETA: 20s - loss: 0.1163 - mean_iou: 0.581 - ETA: 19s - loss: 0.1156 - mean_iou: 0.582 - ETA: 19s - loss: 0.1151 - mean_iou: 0.582 - ETA: 18s - loss: 0.1138 - mean_iou: 0.582 - ETA: 18s - loss: 0.1129 - mean_iou: 0.582 - ETA: 17s - loss: 0.1123 - mean_iou: 0.582 - ETA: 17s - loss: 0.1126 - mean_iou: 0.582 - ETA: 16s - loss: 0.1147 - mean_iou: 0.583 - ETA: 15s - loss: 0.1148 - mean_iou: 0.583 - ETA: 15s - loss: 0.1140 - mean_iou: 0.583 - ETA: 14s - loss: 0.1127 - mean_iou: 0.583 - ETA: 14s - loss: 0.1113 - mean_iou: 0.583 - ETA: 13s - loss: 0.1094 - mean_iou: 0.583 - ETA: 13s - loss: 0.1083 - mean_iou: 0.584 - ETA: 12s - loss: 0.1075 - mean_iou: 0.584 - ETA: 12s - loss: 0.1066 - mean_iou: 0.584 - ETA: 11s - loss: 0.1068 - mean_iou: 0.584 - ETA: 10s - loss: 0.1071 - mean_iou: 0.584 - ETA: 10s - loss: 0.1066 - mean_iou: 0.584 - ETA: 9s - loss: 0.1069 - mean_iou: 0.584 - ETA: 9s - loss: 0.1084 - mean_iou: 0.58 - ETA: 8s - loss: 0.1087 - mean_iou: 0.58 - ETA: 8s - loss: 0.1078 - mean_iou: 0.58 - ETA: 7s - loss: 0.1083 - mean_iou: 0.58 - ETA: 7s - loss: 0.1090 - mean_iou: 0.58 - ETA: 6s - loss: 0.1089 - mean_iou: 0.58 - ETA: 6s - loss: 0.1100 - mean_iou: 0.58 - ETA: 5s - loss: 0.1099 - mean_iou: 0.58 - ETA: 4s - loss: 0.1108 - mean_iou: 0.58 - ETA: 4s - loss: 0.1099 - mean_iou: 0.58 - ETA: 3s - loss: 0.1098 - mean_iou: 0.58 - ETA: 3s - loss: 0.1095 - mean_iou: 0.58 - ETA: 2s - loss: 0.1106 - mean_iou: 0.58 - ETA: 2s - loss: 0.1116 - mean_iou: 0.58 - ETA: 1s - loss: 0.1109 - mean_iou: 0.58 - ETA: 1s - loss: 0.1103 - mean_iou: 0.58 - ETA: 0s - loss: 0.1112 - mean_iou: 0.5876\n",
      "Epoch 00008: val_loss improved from 0.10718 to 0.09990, saving model to model-dsbowl2018-1.h5\n",
      "536/536 [==============================] - 42s 78ms/step - loss: 0.1120 - mean_iou: 0.5878 - val_loss: 0.0999 - val_mean_iou: 0.6019\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528/536 [============================>.] - ETA: 38s - loss: 0.0859 - mean_iou: 0.604 - ETA: 38s - loss: 0.0713 - mean_iou: 0.604 - ETA: 38s - loss: 0.0754 - mean_iou: 0.605 - ETA: 37s - loss: 0.1054 - mean_iou: 0.605 - ETA: 36s - loss: 0.1282 - mean_iou: 0.605 - ETA: 35s - loss: 0.1155 - mean_iou: 0.605 - ETA: 34s - loss: 0.1136 - mean_iou: 0.605 - ETA: 34s - loss: 0.1233 - mean_iou: 0.605 - ETA: 33s - loss: 0.1268 - mean_iou: 0.605 - ETA: 32s - loss: 0.1265 - mean_iou: 0.606 - ETA: 31s - loss: 0.1292 - mean_iou: 0.606 - ETA: 31s - loss: 0.1249 - mean_iou: 0.606 - ETA: 31s - loss: 0.1242 - mean_iou: 0.606 - ETA: 30s - loss: 0.1197 - mean_iou: 0.606 - ETA: 29s - loss: 0.1189 - mean_iou: 0.606 - ETA: 28s - loss: 0.1160 - mean_iou: 0.606 - ETA: 28s - loss: 0.1164 - mean_iou: 0.607 - ETA: 27s - loss: 0.1124 - mean_iou: 0.607 - ETA: 27s - loss: 0.1103 - mean_iou: 0.607 - ETA: 26s - loss: 0.1072 - mean_iou: 0.607 - ETA: 25s - loss: 0.1046 - mean_iou: 0.607 - ETA: 25s - loss: 0.1048 - mean_iou: 0.607 - ETA: 24s - loss: 0.1065 - mean_iou: 0.607 - ETA: 24s - loss: 0.1058 - mean_iou: 0.608 - ETA: 23s - loss: 0.1041 - mean_iou: 0.608 - ETA: 23s - loss: 0.1033 - mean_iou: 0.608 - ETA: 22s - loss: 0.1039 - mean_iou: 0.608 - ETA: 22s - loss: 0.1039 - mean_iou: 0.608 - ETA: 21s - loss: 0.1048 - mean_iou: 0.608 - ETA: 20s - loss: 0.1073 - mean_iou: 0.608 - ETA: 20s - loss: 0.1075 - mean_iou: 0.609 - ETA: 19s - loss: 0.1074 - mean_iou: 0.609 - ETA: 19s - loss: 0.1075 - mean_iou: 0.609 - ETA: 18s - loss: 0.1071 - mean_iou: 0.609 - ETA: 17s - loss: 0.1071 - mean_iou: 0.609 - ETA: 17s - loss: 0.1068 - mean_iou: 0.609 - ETA: 16s - loss: 0.1061 - mean_iou: 0.610 - ETA: 16s - loss: 0.1063 - mean_iou: 0.610 - ETA: 15s - loss: 0.1050 - mean_iou: 0.610 - ETA: 15s - loss: 0.1054 - mean_iou: 0.610 - ETA: 14s - loss: 0.1052 - mean_iou: 0.610 - ETA: 13s - loss: 0.1046 - mean_iou: 0.610 - ETA: 13s - loss: 0.1047 - mean_iou: 0.610 - ETA: 12s - loss: 0.1040 - mean_iou: 0.610 - ETA: 12s - loss: 0.1043 - mean_iou: 0.611 - ETA: 11s - loss: 0.1047 - mean_iou: 0.611 - ETA: 11s - loss: 0.1040 - mean_iou: 0.611 - ETA: 10s - loss: 0.1065 - mean_iou: 0.611 - ETA: 9s - loss: 0.1060 - mean_iou: 0.611 - ETA: 9s - loss: 0.1059 - mean_iou: 0.61 - ETA: 8s - loss: 0.1054 - mean_iou: 0.61 - ETA: 8s - loss: 0.1071 - mean_iou: 0.61 - ETA: 7s - loss: 0.1068 - mean_iou: 0.61 - ETA: 7s - loss: 0.1070 - mean_iou: 0.61 - ETA: 6s - loss: 0.1070 - mean_iou: 0.61 - ETA: 6s - loss: 0.1066 - mean_iou: 0.61 - ETA: 5s - loss: 0.1060 - mean_iou: 0.61 - ETA: 4s - loss: 0.1067 - mean_iou: 0.61 - ETA: 4s - loss: 0.1076 - mean_iou: 0.61 - ETA: 3s - loss: 0.1074 - mean_iou: 0.61 - ETA: 3s - loss: 0.1070 - mean_iou: 0.61 - ETA: 2s - loss: 0.1065 - mean_iou: 0.61 - ETA: 2s - loss: 0.1072 - mean_iou: 0.61 - ETA: 1s - loss: 0.1071 - mean_iou: 0.61 - ETA: 1s - loss: 0.1078 - mean_iou: 0.61 - ETA: 0s - loss: 0.1077 - mean_iou: 0.6139\n",
      "Epoch 00009: val_loss did not improve\n",
      "536/536 [==============================] - 40s 75ms/step - loss: 0.1082 - mean_iou: 0.6140 - val_loss: 0.1040 - val_mean_iou: 0.6245\n",
      "Epoch 10/10\n",
      "528/536 [============================>.] - ETA: 34s - loss: 0.0969 - mean_iou: 0.626 - ETA: 34s - loss: 0.1223 - mean_iou: 0.626 - ETA: 33s - loss: 0.1211 - mean_iou: 0.626 - ETA: 34s - loss: 0.1057 - mean_iou: 0.626 - ETA: 33s - loss: 0.0989 - mean_iou: 0.626 - ETA: 32s - loss: 0.0937 - mean_iou: 0.626 - ETA: 32s - loss: 0.0981 - mean_iou: 0.626 - ETA: 31s - loss: 0.0966 - mean_iou: 0.627 - ETA: 31s - loss: 0.0957 - mean_iou: 0.627 - ETA: 30s - loss: 0.1015 - mean_iou: 0.627 - ETA: 30s - loss: 0.1006 - mean_iou: 0.627 - ETA: 29s - loss: 0.1014 - mean_iou: 0.627 - ETA: 29s - loss: 0.0992 - mean_iou: 0.627 - ETA: 28s - loss: 0.0996 - mean_iou: 0.627 - ETA: 28s - loss: 0.1002 - mean_iou: 0.627 - ETA: 27s - loss: 0.0987 - mean_iou: 0.627 - ETA: 26s - loss: 0.1001 - mean_iou: 0.628 - ETA: 26s - loss: 0.0980 - mean_iou: 0.628 - ETA: 25s - loss: 0.1003 - mean_iou: 0.628 - ETA: 25s - loss: 0.1020 - mean_iou: 0.628 - ETA: 24s - loss: 0.1018 - mean_iou: 0.628 - ETA: 24s - loss: 0.1037 - mean_iou: 0.628 - ETA: 23s - loss: 0.1020 - mean_iou: 0.628 - ETA: 22s - loss: 0.1012 - mean_iou: 0.629 - ETA: 22s - loss: 0.1006 - mean_iou: 0.629 - ETA: 21s - loss: 0.1007 - mean_iou: 0.629 - ETA: 21s - loss: 0.1020 - mean_iou: 0.629 - ETA: 20s - loss: 0.1042 - mean_iou: 0.629 - ETA: 20s - loss: 0.1049 - mean_iou: 0.629 - ETA: 19s - loss: 0.1064 - mean_iou: 0.629 - ETA: 19s - loss: 0.1065 - mean_iou: 0.629 - ETA: 18s - loss: 0.1063 - mean_iou: 0.630 - ETA: 17s - loss: 0.1055 - mean_iou: 0.630 - ETA: 17s - loss: 0.1061 - mean_iou: 0.630 - ETA: 16s - loss: 0.1059 - mean_iou: 0.630 - ETA: 16s - loss: 0.1051 - mean_iou: 0.630 - ETA: 15s - loss: 0.1054 - mean_iou: 0.630 - ETA: 15s - loss: 0.1041 - mean_iou: 0.630 - ETA: 14s - loss: 0.1036 - mean_iou: 0.630 - ETA: 14s - loss: 0.1026 - mean_iou: 0.630 - ETA: 13s - loss: 0.1040 - mean_iou: 0.631 - ETA: 13s - loss: 0.1031 - mean_iou: 0.631 - ETA: 12s - loss: 0.1033 - mean_iou: 0.631 - ETA: 12s - loss: 0.1031 - mean_iou: 0.631 - ETA: 11s - loss: 0.1022 - mean_iou: 0.631 - ETA: 11s - loss: 0.1011 - mean_iou: 0.631 - ETA: 10s - loss: 0.1013 - mean_iou: 0.631 - ETA: 10s - loss: 0.1017 - mean_iou: 0.631 - ETA: 9s - loss: 0.1019 - mean_iou: 0.631 - ETA: 8s - loss: 0.1016 - mean_iou: 0.63 - ETA: 8s - loss: 0.1018 - mean_iou: 0.63 - ETA: 7s - loss: 0.1016 - mean_iou: 0.63 - ETA: 7s - loss: 0.1009 - mean_iou: 0.63 - ETA: 6s - loss: 0.1003 - mean_iou: 0.63 - ETA: 6s - loss: 0.1008 - mean_iou: 0.63 - ETA: 5s - loss: 0.1005 - mean_iou: 0.63 - ETA: 5s - loss: 0.1000 - mean_iou: 0.63 - ETA: 4s - loss: 0.1007 - mean_iou: 0.63 - ETA: 4s - loss: 0.1000 - mean_iou: 0.63 - ETA: 3s - loss: 0.1003 - mean_iou: 0.63 - ETA: 3s - loss: 0.1006 - mean_iou: 0.63 - ETA: 2s - loss: 0.1013 - mean_iou: 0.63 - ETA: 2s - loss: 0.1008 - mean_iou: 0.63 - ETA: 1s - loss: 0.1006 - mean_iou: 0.63 - ETA: 1s - loss: 0.1004 - mean_iou: 0.63 - ETA: 0s - loss: 0.1002 - mean_iou: 0.6338\n",
      "Epoch 00010: val_loss improved from 0.09990 to 0.09564, saving model to model-dsbowl2018-1.h5\n",
      "536/536 [==============================] - 39s 73ms/step - loss: 0.1009 - mean_iou: 0.6340 - val_loss: 0.0956 - val_mean_iou: 0.6433\n",
      "603/603 [==============================] - ETA: 18 - ETA: 15 - ETA: 13 - ETA: 12 - ETA: 11 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 15s 25ms/step\n",
      "67/67 [==============================] - ETA:  - ETA:  - 2s 25ms/step\n",
      "65/65 [==============================] - ETA:  - ETA:  - 2s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.2, batch_size=8, epochs=10, \n",
    "                    callbacks=[earlystopper, checkpointer])\n",
    "                    \n",
    "                    \n",
    "# Predict on train, val and test\n",
    "model = load_model('model-dsbowl2018-1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))\n",
    "    \n",
    "    \n",
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.to_csv('sub-dsbowl2018-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0114f484a16c152baa2d82fdd43740880a762c93f436c8...</td>\n",
       "      <td>44595 2 44848 9 45101 14 45357 14 45612 16 458...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0114f484a16c152baa2d82fdd43740880a762c93f436c8...</td>\n",
       "      <td>27992 3 28247 5 28502 6 28759 5 29016 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0114f484a16c152baa2d82fdd43740880a762c93f436c8...</td>\n",
       "      <td>49769 5 50023 9 50276 13 50531 15 50786 17 510...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0114f484a16c152baa2d82fdd43740880a762c93f436c8...</td>\n",
       "      <td>10637 5 10890 10 11144 12 11399 14 11654 15 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0114f484a16c152baa2d82fdd43740880a762c93f436c8...</td>\n",
       "      <td>30876 6 31130 9 31374 22 31628 24 31882 26 321...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ImageId  \\\n",
       "0  0114f484a16c152baa2d82fdd43740880a762c93f436c8...   \n",
       "1  0114f484a16c152baa2d82fdd43740880a762c93f436c8...   \n",
       "2  0114f484a16c152baa2d82fdd43740880a762c93f436c8...   \n",
       "3  0114f484a16c152baa2d82fdd43740880a762c93f436c8...   \n",
       "4  0114f484a16c152baa2d82fdd43740880a762c93f436c8...   \n",
       "\n",
       "                                       EncodedPixels  \n",
       "0  44595 2 44848 9 45101 14 45357 14 45612 16 458...  \n",
       "1            27992 3 28247 5 28502 6 28759 5 29016 3  \n",
       "2  49769 5 50023 9 50276 13 50531 15 50786 17 510...  \n",
       "3  10637 5 10890 10 11144 12 11399 14 11654 15 11...  \n",
       "4  30876 6 31130 9 31374 22 31628 24 31882 26 321...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
